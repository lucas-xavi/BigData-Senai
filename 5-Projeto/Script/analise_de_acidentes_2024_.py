# -*- coding: utf-8 -*-
"""Analise_De_Acidentes_2024_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ZLWtRwPEGSD3hw_DsYvh08pgx_7cZXA
"""

# Importando o PySpark
from pyspark.sql import SparkSession

# Criando uma sessão do Spark e adicionando o JAR spark-excel
spark = SparkSession.builder.appName('Análise Acidentes 2024') \
.config('spark.jars.package', 'com.crealytics:spark-excel_2.12:0.13.7') \
.getOrCreate()

# Caminho para o CSV
csv_file_path = '/content/acidentes2024_todas_causas_tipos_vs2.csv'

# Lendo o arquivo CSV com Pyspark, especificando o delimitador e codificação
df_spark = spark.read.csv(csv_file_path, header = True, sep=';', inferSchema=True, encoding='UTF-8')

# Exibindo o esquema da tabela
#df_spark.printSchema()

# Exibindo o DataFrame, somente as 5 primeiras linhas
df_spark.show(5)

# Excluíndo os dados nullos do DataFrame
df_spark = df_spark.replace(["NA", "NULL"], None).na.drop(subset=["id", "data_inversa", "horario", "uf", "br", "km"])

# Excluíndo registros duplicados pela coluna id
df_distinct = df_spark.dropDuplicates(['id'])

# Fazendo contagem de acidentes por dia da semana
df_distinct.groupBy('dia_semana').count().orderBy('count', ascending=False).show()

# Fazendo contagem por condição metereologica e o tipo de pista
df_distinct.groupBy('condicao_metereologica', 'tipo_pista').count().orderBy('condicao_metereologica', ascending=True).show()

from pyspark.sql.functions import round, avg

df_distinct.groupBy('br', 'uf') \
.agg(round(avg('km'), 2).alias('avg_km')) \
.orderBy('uf', ascending=True).show()

# Filtrando média de km por UF = São Paulo
from pyspark.sql.functions import when, col
df_avgkm_br = df_distinct.filter(df_distinct.uf == 'SP') \
.groupBy('br') \
.agg(round(avg('km'), 2).alias('avg_km')) \
.orderBy('br', ascending=True)
df_avgkm_br.show()

# Importandando a biblioteca Pandas para a conversão do DataFrame spark para pandas
import pandas as pd
df_avgkm_br_pd = df_avgkm_br.toPandas()

# Importação das biblioteca para a criação do gráfico
import matplotlib.pyplot as plt
import seaborn as sns

# Criação do gráfico
plt.figure(figsize=(10,6))
sns.barplot(x='avg_km', y='br', data=df_avgkm_br_pd)
plt.title('Análise de acidentes por Rodovia Federal')
plt.xlabel('Km/h (Velocidade do do veículo)')
plt.ylabel('Rodovias Federais')
plt.show()

# Código adicionado no dia 15/04, depois da segunda análise para averiguar, a quantidade de registro por Id
df_spark.groupBy('id').count().orderBy('count', ascending=False).show()

# Finalizando a sessão do spark
spark.stop()